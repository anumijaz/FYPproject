{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Following Liabraries For Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition # must install this liabray using pip install face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is the Train function to train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses KNN_Classifier to train model for face recognition\n",
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "    #initialize two lists for storing encoding images and their respective label\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through each person in the training directory to get respected label of image  \n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Loop through each training image for the current person in the path\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)# convert image to gray scale.\n",
    "            #Use HOG face detection Classifier to find faces in Given Image\n",
    "            face_bounding_boxes = face_recognition.face_locations(rgb,model='Hog')\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                # If there are no people (or too many people) in a training image, skip that image.\n",
    "                if verbose:\n",
    "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                # Add face encoding of current image to the training list X and its respective label in list Y\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    # Create and train the KNN_Classifier with given n_neighbours\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier for furthur Use\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFunction():\n",
    "    print(\"Training KNN classifier...\")\n",
    "    classifier = train(\"TrainingImage\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call this trainFunction for training of model on given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "trainFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict function that Recognizes faces in given image using a trained KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_frame,knn_clf=None, model_path=None, distance_threshold=0.5):\n",
    "    \n",
    "    # Load a trained KNN model (if one was passed in)\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "    #For face detection Again convert frame into gray scale\n",
    "    rgb = cv2.cvtColor(X_frame, cv2.COLOR_BGR2RGB)\n",
    "    #Use HOG classifier for finding face in given frame. \n",
    "    X_face_locations = face_recognition.face_locations(rgb,model='Hog')\n",
    "    \n",
    "    # If no faces are found in the image, return an empty result.\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    # Find encodings for faces in the X_frame\n",
    "    faces_encodings = face_recognition.face_encodings(X_frame, known_face_locations=X_face_locations)\n",
    "\n",
    "    # Use the KNN model to find the best matches for the test face\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=2)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    # Predict classes and remove classifications that aren't within the threshold\n",
    "    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show_perdiction_on_label function is used to shows the face recognition results visually by drawing rectangle with recognized label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction_labels_on_image(frame, predictions):\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        # enlarge the predictions for the full sized image.\n",
    "        top *= 2\n",
    "        right *= 2\n",
    "        bottom *= 2\n",
    "        left *= 2\n",
    "        # Draw a box around the face using the Pillow module\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "        # There's a bug in Pillow where it blows up with non-UTF-8 text\n",
    "        # when using the default bitmap font\n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        # Draw a label with a name below the face on rectangle shape\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "       \n",
    "\n",
    "    # Remove the drawing library from memory as per the Pillow docs.\n",
    "    del draw\n",
    "    # Save image in open-cv format to be able to show it.\n",
    "\n",
    "    opencvimage = np.array(pil_image)\n",
    "    return opencvimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Now finally Setting up Camera for Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting cameras up...\n"
     ]
    }
   ],
   "source": [
    "process_this_frame = 4\n",
    "print('Setting cameras up...')\n",
    "# multiple cameras can be used with the format url = 'http://username:password@camera_ip:port'\n",
    "#url = 'http://admin:admin12345@192.168.1.1:8800'\n",
    "#Use this format to use Mobile Camera\n",
    "#url='http://192.168.0.100:4747/video'\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    #print('welcome')\n",
    "    if ret:\n",
    "        # Different resizing options can be chosen based on desired program runtime.\n",
    "        # Image resizing for more stable streaming\n",
    "        img = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        process_this_frame = process_this_frame + 1\n",
    "        if process_this_frame % 5 == 0:\n",
    "            predictions = predict(img, model_path=\"trained_knn_model.clf\")\n",
    "        frame = show_prediction_labels_on_image(frame, predictions)\n",
    "        cv2.imshow('camera', frame)\n",
    "        if ord('q') == cv2.waitKey(10):\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
